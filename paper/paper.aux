\relax 
\citation{pearson1901}
\citation{sirovich87}
\citation{turk91}
\citation{shlens09}
\citation{borja09}
\citation{shlens09}
\citation{borja09}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Image reconstruction with PCA}{1}}
\citation{borja09}
\citation{borja09}
\citation{borja09}
\@writefile{toc}{\contentsline {section}{\numberline {III}Classification using reconstruction}{2}}
\newlabel{total_error}{{6}{2}}
\newlabel{weighted_total_error}{{8}{2}}
\citation{cbcl}
\citation{jiang09}
\citation{gonzalez01}
\citation{code}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Experiments}{3}}
\citation{ga}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Comparison of area under the curve (AUC) of the classifiers based on grayscale error, edge error, and total error, respectively, for many values of $k$. The AUCs of the edge-based classifier are always larger then the grayscale-based classifier. This indicates edge errors are more relevant to the classification.}}{4}}
\newlabel{table-gray-vs-edge}{{I}{4}}
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces Weights that produced best classification rates for each value of $k$. Note that the weights associated to edge errors are usually larger than the errors associated to grayscale errors, what reinforces the greater importance of the edge errors to the classification.}}{4}}
\newlabel{table-weights}{{II}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Conclusion}{4}}
\citation{li05}
\bibstyle{IEEEtran}
\bibdata{paper}
\bibcite{pearson1901}{1}
\bibcite{sirovich87}{2}
\bibcite{turk91}{3}
\bibcite{shlens09}{4}
\bibcite{borja09}{5}
\bibcite{cbcl}{6}
\bibcite{jiang09}{7}
\bibcite{gonzalez01}{8}
\bibcite{code}{9}
\bibcite{li05}{10}
\@writefile{toc}{\contentsline {section}{References}{5}}
